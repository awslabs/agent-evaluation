# Amazon SageMaker endpoints

Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows. SageMaker endpoints are used to host ML models for real-time inference use cases. For more information, visit the AWS documentation [here](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html).

!!! info

    The current implementation uses JSON to encode the data sent in requests and decode the data received in responses.
    Please ensure that your SageMaker endpoint can handle requests and responses with the Content-Type and Accept headers
    set to `application/json` before proceeding.

## Prerequisites

The principal must have the following permissions:

- [InvokeEndpoint](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html)

## Configurations

```yaml title="agenteval.yml"
target:
  type: sagemaker-endpoint
  endpoint_name:
  request_body:
  input_path:
  output_path:
  custom_attributes:
  target_model:
  target_variant:
  target_container_hostname:
  inference_component_name:
```

`endpoint_name` _(string)_

The name of the Amazon SageMaker endpoint.

---

`request_body` _(map)_

The data that is sent to the endpoint, which includes a placeholder for the prompt. During a run, the placeholder will be replaced by a prompt generated by the Evaluator. For example:

```yaml
request_body:
  input_text: None # prompt
  temperature: 0.1
```

---

`input_path` _(string)_

A [JSONPath expression](https://github.com/h2non/jsonpath-ng?tab=readme-ov-file#jsonpath-syntax) to match the field for the input prompt in the request body. For the `request_body` below:

```yaml
request_body:
  input_text: None # prompt
  temperature: 0.1
```

The `input_path` would be `$.input_text`.

---

`output_path` _(string)_

A [JSONPath expression](https://github.com/h2non/jsonpath-ng?tab=readme-ov-file#jsonpath-syntax) to match the generated text in the response body. For example, if the endpoint returns the following:

```json
[{ "generated_text": "Hello!" }]
```

The `output_path` would be `$.[0].generated_text`.

---

`custom_attributes` _(string; optional)_

Provides additional information about a request for an inference submitted to a model hosted at an Amazon SageMaker endpoint.

---

`target_model` _(string; optional)_

The model to request for inference when invoking a multi-model endpoint.

---

`target_variant` _(string; optional)_

The production variant to send the inference request to when invoking an endpoint that is running two or more variants.

---

`target_container_hostname` _(string; optional)_

The hostname of the container to invoke if the endpoint hosts multiple containers and is configured to use direct invocation.

---

`inference_component_name` _(string; optional)_

The name of the inference component to invoke if the endpoint hosts one or more inference components.

---
